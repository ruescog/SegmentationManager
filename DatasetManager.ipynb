{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is an \"import\" in .py files\n",
    "%run utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory checking\n",
    "import os\n",
    "from os import path as osp\n",
    "\n",
    "# utils\n",
    "from imutils import paths\n",
    "from PIL import Image\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# mmsegmentation\n",
    "from mmseg.datasets.builder import DATASETS\n",
    "from mmseg.datasets.custom import CustomDataset\n",
    "\n",
    "# fastai\n",
    "import torch\n",
    "from torch.utils.data import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetManager():\n",
    "    \"\"\"\n",
    "    DatasetManager is an abstract class. It defines the way to build a correct dataset that can be used to build segmentation models.\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, *,\n",
    "        img_prefix = \"\", mask_prefix = \"\", img_suffix = \"\", mask_suffix = \"\", delete_prefixes = True,\n",
    "        img_map = None, mask_map = None, check_maps = True, check_map_fails = None,\n",
    "        convert_masks = True, noise_class = 0):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Creates a DatasetManager with the specified configuration.\n",
    "\n",
    "        Parameters:\n",
    "        root_dir (str): root directory of the dataset.\n",
    "        img_prefix (str, \"\"): images prefix.\n",
    "        mask_prefix (str, \"\"): masks prefix.\n",
    "        img_suffix (str, \"\"): images suffix. Calculated using the mode if not supplied.\n",
    "        mask_suffix (str, \"\"): masks suffix. Calculated using the mode if not supplied.\n",
    "        delete_prefixes (boolean, True): if True, renames all the files in the dataset deleting their prefixes.\n",
    "        img_map (function): map function between images and masks. If None, prefix and suffix are used to create the default map function.\n",
    "        mask_map (function): map function between masks and images. If None, prefix and suffix are used to create the default map function.\n",
    "        check_maps (boolean, True): if True, check if the image -> mask and mask -> imagen relations are bijective (1 to 1).\n",
    "        check_map_fails(tuple[function, function], tuple[move, move]): Tuple of functions to apply if the relation is not bijective. The first function is applied to images and the second is applied to masks. By default, Move the failed files to a new directory named \"map_fails\" in \"dataset\".\n",
    "        convert_mask (boolean, True): if is needed to convert the masks into id maps.\n",
    "        noise_class (int, 0): the noise class id. If convert_masks is required, it is used to map unknown classes into this class.\n",
    "        \n",
    "        Returns:\n",
    "        dm (DatasetManager): the built DatasetManager.\n",
    "        \"\"\"\n",
    "        # pathing params\n",
    "        self.root_dir_ = root_dir\n",
    "        self.img_dir_ = osp.join(self.root_dir_, \"images\")\n",
    "        self.mask_dir_ = osp.join(self.root_dir_, \"masks\")\n",
    "        self.codes_file_ = osp.join(self.root_dir_, \"codes.json\")\n",
    "\n",
    "        # cheching dirs and files\n",
    "        self.__check_dir_architecture__()\n",
    "\n",
    "        # prefix and suffix data\n",
    "        self.img_prefix_ = img_prefix\n",
    "        self.mask_prefix_ = mask_prefix\n",
    "        self.img_suffix_ = img_suffix if img_suffix else self.__get_suffix__(self.img_dir_)\n",
    "        self.mask_suffix_ = mask_suffix if mask_suffix else self.__get_suffix__(self.mask_dir_)\n",
    "        \n",
    "        # maping image - mask\n",
    "        self.img_map_ = img_map if img_map else self.__get_default_img_map__()\n",
    "        self.mask_map_ = mask_map if mask_map else self.__get_default_mask_map__()\n",
    "        \n",
    "        # deleing prefixes if requested. If the are no prefixes, no conversion is needed\n",
    "        if delete_prefixes and (self.img_prefix_ or self.mask_prefix_):\n",
    "            self.__delete_prefixes__()    \n",
    "\n",
    "        # checking the map if requested\n",
    "        if check_maps:\n",
    "            if not check_map_fails:\n",
    "                check_map_fails = self.__get_default_check_map_fail__()\n",
    "                check_map_fails = (check_map_fails, check_map_fails)\n",
    "            self.__check_maps__(check_map_fails)\n",
    "        \n",
    "        # converting the masks if requested\n",
    "        if convert_masks:\n",
    "            self.__convert_masks__(noise_class)\n",
    "        else:\n",
    "            self.__check_masks__()\n",
    "        \n",
    "        # gets the codes\n",
    "        with open(self.codes_file_, \"r\") as codes_file:\n",
    "            codes = json.load(codes_file)\n",
    "        \n",
    "        # class codes\n",
    "        self.class_names_ = codes.keys()\n",
    "        \n",
    "        # palette\n",
    "        self.palette_ = {key: value[2] for key, value in codes.items()}\n",
    "\n",
    "    @AOP.logger(\"All the files needed exist in the root directory.\")\n",
    "    @AOP.excepter(FileNotFoundError)\n",
    "    def __check_dir_architecture__(self):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Check all the dataset default architecture (root, images, masks directory and codes file).\n",
    "        \n",
    "        Parameters:\n",
    "        None.\n",
    "        \n",
    "        Returns:\n",
    "        None.\n",
    "        \"\"\"\n",
    "        if (not osp.isdir(self.root_dir_)\n",
    "            or not osp.isdir(osp.join(self.root_dir_, \"images\"))\n",
    "            or not osp.isdir(osp.join(self.root_dir_, \"masks\"))\n",
    "            or not osp.isfile(self.codes_file_)):\n",
    "            raise FileNotFoundError(\"The root, 'images', 'masks' or 'codes.json' files do not exist.\")\n",
    "\n",
    "    def __get_suffix__(self, path):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Impute the suffix of the elements in path using the mode.\n",
    "        \n",
    "        Parameters:\n",
    "        path (str): the path to search the suffix.\n",
    "        \n",
    "        Returns:\n",
    "        mode (str): the suffix mode for all the files in the path.\n",
    "        \"\"\"\n",
    "        # the impute suffix is calculated directly from the data using the mode\n",
    "        suffixes = [file.split(\".\")[-1] for file in paths.list_files(path)]\n",
    "        return \".\" + max(set(suffixes), key = suffixes.count)\n",
    "    \n",
    "    @AOP.logger(\"All the prefixes were deleted.\")\n",
    "    def __delete_prefixes__(self):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Rename all the images and masks with a common name (plus extension).\n",
    "        \n",
    "        Parameters:\n",
    "        None.\n",
    "        \n",
    "        Returns:\n",
    "        None.\n",
    "        \"\"\"\n",
    "        # base variables\n",
    "        img_files = list(paths.list_files(self.img_dir_, validExts = self.img_suffix_))\n",
    "        mask_files = list(paths.list_files(self.mask_dir_, validExts = self.mask_suffix_))\n",
    "\n",
    "        # renaming the images\n",
    "        for file in img_files:\n",
    "            old_name = osp.basename(file)\n",
    "            new_name = old_name[len(self.img_prefix_):]\n",
    "            os.rename(file, osp.join(self.img_dir_, new_name))\n",
    "        \n",
    "        # renaming the masks\n",
    "        for file in mask_files:\n",
    "            old_name = osp.basename(file)\n",
    "            new_name = old_name[len(self.mask_prefix_):]\n",
    "            os.rename(file, osp.join(self.mask_dir_, new_name))\n",
    "\n",
    "        # dataset reconfiguration after conversion\n",
    "        self.img_prefix_ = \"\"\n",
    "        self.mask_prefix_ = \"\"\n",
    "        self.img_map_ = self.__get_default_img_map__()\n",
    "        self.mask_map_ = self.__get_default_mask_map__()\n",
    "    \n",
    "    def __get_default_img_map__(self):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Return the mask relationed with this image.\n",
    "        \n",
    "        Parameters:\n",
    "        None.\n",
    "        \n",
    "        Returns:\n",
    "        f (function): the map function between a image and it's mask.\n",
    "        \"\"\"\n",
    "        return lambda image: osp.join(\n",
    "            self.mask_dir_, self.mask_prefix_ + str(image)[len(self.img_prefix_) : -len(self.img_suffix_)] + self.mask_suffix_)\n",
    "    \n",
    "    def __get_default_mask_map__(self):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Defines the image relationed with this mask.\n",
    "        \n",
    "        Parameters:\n",
    "        None.\n",
    "        \n",
    "        Returns:\n",
    "        f (function): the map function between a mask and it's image.\n",
    "        \"\"\"\n",
    "        return lambda mask: osp.join(\n",
    "            self.img_dir_, self.img_prefix_ + str(mask)[len(self.mask_prefix_) : -len(self.mask_suffix_)] + self.img_suffix_)\n",
    "    \n",
    "    def __get_default_check_map_fail__(self):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Defines the default action to do when a map check fails. Moves the file with errors to an other directory.\n",
    "        \n",
    "        Parameters:\n",
    "        None.\n",
    "        \n",
    "        Return:\n",
    "        f (function): the move function to use if the check_map fails.\n",
    "        \"\"\"\n",
    "        # naming this function is necessary to achieve greater transparency\n",
    "        def move(file):\n",
    "            # gets or creates the error directory\n",
    "            error_dir = osp.join(self.root_dir_, \"map_fails\")\n",
    "            if not osp.isdir(error_dir):\n",
    "                os.mkdir(error_dir)\n",
    "            \n",
    "            # move the file to the directory\n",
    "            file_name = osp.basename(file)\n",
    "            os.rename(file, osp.join(self.root_dir_, \"map_fails\", file_name))\n",
    "        \n",
    "        return move\n",
    "                      \n",
    "    def __check_maps_common_loop__(self, files, used_map, check_map_fail):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Code abstraction for avoid replication.\n",
    "        \n",
    "        Parameters:\n",
    "        files (list[str]): the list of files to check the map with.\n",
    "        used_map (function): the map function being used.\n",
    "        check_map_fail (function): the function to apply if the map fails.\n",
    "\n",
    "        Returns:\n",
    "        errors (int): the number of error encountered in the process.\n",
    "        \"\"\"\n",
    "        errors = 0\n",
    "        for file in files:\n",
    "            # loop variables\n",
    "            file_name = osp.basename(file)\n",
    "            mapped_file = used_map(file_name)\n",
    "            \n",
    "            # if mapped_file does not exist, the file has no elements to map with, the relation is not bijective\n",
    "            if not osp.isfile(mapped_file):\n",
    "                check_map_fail(file)\n",
    "                errors += 1\n",
    "            \n",
    "            # otherwise, the mapped_file is unique (file format restriction), so the relation can be bijective.\n",
    "        return errors\n",
    "    \n",
    "    @AOP.logger(\"VALUE errors were encounted checking the relations maps. 'check_map_fails' functions were applied to those files.\")\n",
    "    def __check_maps__(self, check_map_fail):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Check the mapping between images and masks.\n",
    "        \n",
    "        Parameters:\n",
    "        check_map_fails(((function, function)), (move, move)): Tuple of functions to apply if the relation is not bijective. The first function is applied to images and the second is applied to masks. By default, Move the failed files to a new directory named \"map_fails\" in \"dataset\".\n",
    "        \n",
    "        Returns:\n",
    "        errors (int): the number of errors encountered cheching the maps.\n",
    "        \"\"\"\n",
    "        # initial variables\n",
    "        img_files = paths.list_files(self.img_dir_, validExts = self.img_suffix_)\n",
    "        mask_files = paths.list_files(self.mask_dir_, validExts = self.mask_suffix_)\n",
    "        \n",
    "        # checks the maps\n",
    "        errors = self.__check_maps_common_loop__(img_files, self.img_map_, check_map_fail[0])\n",
    "        errors += self.__check_maps_common_loop__(mask_files, self.mask_map_, check_map_fail[1])\n",
    "        \n",
    "        return errors\n",
    "    \n",
    "    @AOP.excepter(MaskFormatDoesNotMatch, ignore = True)\n",
    "    def __check_masks__(self):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Checks the masks and raises an advise if the format can raise an exception.\n",
    "        \n",
    "        Parameters:\n",
    "        None.\n",
    "\n",
    "        Returns:\n",
    "        None.\n",
    "        \"\"\"\n",
    "        masks = list(paths.list_images(self.mask_dir_))\n",
    "        \n",
    "        for mask in masks:\n",
    "            mask_data = Image.open(mask)\n",
    "            shape = len(np.array(mask_data).shape)\n",
    "            if shape != 2:\n",
    "                raise MaskFormatDoesNotMatch(\"The masks format is not correct.\")\n",
    "\n",
    "    @AOP.logger(\"Converted all the masks. Encountered VALUE masks with noise.\")\n",
    "    def __convert_masks__(self, noise_class):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Checks and converts the masks if requested.\n",
    "        \n",
    "        Parameters:\n",
    "        noise_class (int): the class to map the noise.\n",
    "\n",
    "        Returns:\n",
    "        noise (int): the number of masks with noise.\n",
    "        \"\"\"\n",
    "        # initial variables\n",
    "        masks = list(paths.list_images(self.mask_dir_))\n",
    "        with open(self.codes_file_, \"r\") as f:\n",
    "            codes = json.load(f)\n",
    "\n",
    "        codes_ids = {value[0] for value in codes.values()}\n",
    "        noise = 0\n",
    "\n",
    "        # convert all the masks using the codes file\n",
    "        for mask in masks:\n",
    "            # loads the image\n",
    "            mask_data = Image.open(mask)\n",
    "            converted_mask = mask_data.convert(\"P\")\n",
    "\n",
    "            # creates a np array with the image data\n",
    "            x = np.array(converted_mask)\n",
    "\n",
    "            # maps it\n",
    "            for value in codes.values():\n",
    "                class_value = value[0]\n",
    "                map_value = value[1]\n",
    "                x[x == map_value] = class_value\n",
    "\n",
    "            # looks for noise in the conversion\n",
    "            real_classes = np.unique(x)\n",
    "            if len(real_classes) > len(codes):\n",
    "                for real_class in real_classes:\n",
    "                    if real_class not in codes_ids:\n",
    "                        x[x == real_class] = noise_class\n",
    "                        noise += 1\n",
    "\n",
    "            # saves the result\n",
    "            converted_mask = Image.fromarray(x)\n",
    "            converted_mask.save(mask)\n",
    "\n",
    "        return noise\n",
    "\n",
    "    def get_images(self):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Gets the list of images in the dataset.\n",
    "        \n",
    "        Parameters:\n",
    "        None.\n",
    "        \n",
    "        Returns:\n",
    "        paths (List[str]): the list of images paths in the dataset.\n",
    "        \"\"\"\n",
    "        return list(paths.list_images(self.img_dir_))\n",
    "\n",
    "    def get_codes_template():\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Gets the template for the codes file.\n",
    "        \n",
    "        Parameters:\n",
    "        None.\n",
    "        \n",
    "        Returns:\n",
    "        d (dict): the template.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"class_name_1\": [\"id_class_1\", \"mapped_id_class_1\", [\"R value RGB for class 1\", \"G value RGB for class 1\", \"B value RGB for class 1\"]],\n",
    "            \"class_name_2\": [\"id_class_2\", \"mapped_id_class_2\", [\"R value RGB for class 2\", \"G value RGB for class 2\", \"B value RGB for class 2\"]]\n",
    "        }\n",
    "    \n",
    "    @AOP.excepter(NotImplementedError)\n",
    "    def build_dataset(self):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Constructs a dataset.\n",
    "        \n",
    "        Parameters:\n",
    "        None.\n",
    "        \n",
    "        Returns:\n",
    "        None.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"You can not use this abstract class to build the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetManagerMMSegmentation(DatasetManager):\n",
    "    \"\"\"\n",
    "    DatasetManagerMMSegmentation defines the way to build a MMSegmentation dataset from a DatasetManager.\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, *, img_prefix = \"\", mask_prefix = \"\", img_suffix = \"\", mask_suffix = \"\",\n",
    "        delete_prefixes = True, img_map = None, mask_map = None, check_maps = True, check_map_fails = None,\n",
    "        convert_masks = True, noise_class = 0, name = \"GenericDataset\"):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Creates a DatasetManagerMMSegmentation with the specified configuration.\n",
    "\n",
    "        Parameters:\n",
    "        root_dir (str): root directory of the dataset.\n",
    "        img_prefix (str, \"\"): images prefix.\n",
    "        mask_prefix (str, \"\"): masks prefix.\n",
    "        img_suffix (str, \"\"): images suffix. Calculated using the mode if not supplied.\n",
    "        mask_suffix (str, \"\"): masks suffix. Calculated using the mode if not supplied.\n",
    "        delete_prefixes (boolean, True): if True, renames all the files in the dataset deleting their prefixes.\n",
    "        img_map (function): map function between images and masks. If None, prefix and suffix are used to create the default map function.\n",
    "        mask_map (function): map function between masks and images. If None, prefix and suffix are used to create the default map function.\n",
    "        check_maps (boolean, True): if True, check if the image -> mask and mask -> imagen relations are bijective (1 to 1).\n",
    "        check_map_fails(((function, function)), (move, move)): Tuple of functions to apply if the relation is not bijective. The first function is applied to images and the second is applied to masks. By default, Move the failed files to a new directory named \"map_fails\" in \"dataset\".\n",
    "        convert_masks (boolean, True): if is needed to convert the masks into id maps.\n",
    "        noise_class (int, 0): the noise class id. If convert_masks is required, it is used to map unknown classes into this class.\n",
    "        name (str): the name for the dataset.\n",
    "        \n",
    "        Returns:\n",
    "        dm (DatasetManagerMMSegmentation): the built DatasetManagerMMSegmentation.\n",
    "        \"\"\"\n",
    "        super().__init__(root_dir, img_prefix = img_prefix, mask_prefix = mask_prefix, img_suffix = img_suffix,\n",
    "                        mask_suffix = mask_suffix, delete_prefixes = delete_prefixes, img_map = img_map, mask_map = mask_map,\n",
    "                        check_maps = check_maps, check_map_fails = check_map_fails, convert_masks = convert_masks,\n",
    "                        noise_class = noise_class)\n",
    "        \n",
    "        self.name_ = name\n",
    "\n",
    "    def from_dataset_manager(dataset, name = \"GenericDataset\"):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Gets the representation of a DatasetManagerMMSementation from a generic dataset.\n",
    "        \n",
    "        Parameters:\n",
    "        dataset (DatasetManager): the generic dataset.\n",
    "        \n",
    "        Returns:\n",
    "        dataset (DatasetManagerMMSegmentation): the particular dataset.\n",
    "        \"\"\"\n",
    "        return DatasetManagerMMSegmentation(root_dir = dataset.root_dir_, img_prefix = dataset.img_prefix_,\n",
    "                                            mask_prefix = dataset.mask_prefix_, img_suffix = dataset.img_suffix_,\n",
    "                                            mask_suffix = dataset.mask_suffix_, delete_prefixes = True,\n",
    "                                            img_map = dataset.img_map_, mask_map = dataset.mask_map_,\n",
    "                                            check_maps = True, check_map_fails = None,\n",
    "                                            convert_masks = True, noise_class = 0, name = name)\n",
    "\n",
    "    def build_dataset(self):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Builds a mmsegmentation dataset from the data.\n",
    "        \n",
    "        Parameters:\n",
    "        None.\n",
    "        \n",
    "        Returns:\n",
    "        name (str): the name of the dataset.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # creates and registers the new dataset class\n",
    "            @DATASETS.register_module(name = self.name_) # can raise KeyError exception\n",
    "            class GenericDataset(CustomDataset):\n",
    "                CLASSES = list(self.class_names_)\n",
    "                PALETTE = list(self.palette_.values())\n",
    "\n",
    "                def __init__(_, split, **kwargs):\n",
    "                    super().__init__(\n",
    "                        img_suffix = self.img_suffix_,\n",
    "                        seg_map_suffix = self.mask_suffix_,\n",
    "                        split = split,\n",
    "                        **kwargs)\n",
    "            \n",
    "            return self.name_\n",
    "\n",
    "        except KeyError:\n",
    "            # if the name is duplicated, tries to use a diferent name\n",
    "            self.name_ = str(time.time()).replace(\".\", \"\")\n",
    "            return self.build_dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
