{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonathan/.virtualenvs/mmseg/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "from os import path as osp\n",
    "import os\n",
    "import re\n",
    "import yaml\n",
    "\n",
    "from enum import Enum, EnumMeta\n",
    "\n",
    "# implemented libraries\n",
    "import semtorch\n",
    "import segmentation_models_pytorch as smp\n",
    "import segmentron\n",
    "from mmseg.apis import set_random_seed, train_segmentor\n",
    "from mmseg.datasets import build_dataset as build_ds\n",
    "from mmseg.models import build_segmentor\n",
    "\n",
    "# fastai\n",
    "import fastai\n",
    "from fastai.callback.progress import CSVLogger\n",
    "from fastai.metrics import DiceMulti\n",
    "from fastai.torch_core import trainable_params\n",
    "\n",
    "# mmcv\n",
    "from mmcv import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is an \"import\" in .py files\n",
    "%run utils.ipynb\n",
    "%run DatasetManager.ipynb\n",
    "%run TransformManager.ipynb\n",
    "%run ValidationManager.ipynb\n",
    "%run DataLoaderManager.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DirectValueMeta(EnumMeta):\n",
    "    def __getattribute__(self, name):\n",
    "        value = super().__getattribute__(name)\n",
    "        if isinstance(value, self):\n",
    "            value = value.value\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARCHITECTURE(Enum, metaclass = DirectValueMeta):\n",
    "    \"\"\"\n",
    "    This Enum class defines all the possible architectures that can be used.\n",
    "    \"\"\"\n",
    "    ANN = \"ann\"\n",
    "    APCNET = \"apcnet\"\n",
    "    \n",
    "    BISENET = \"bisenet\", \"bisenetv1\"\n",
    "    BISENETV2 = \"bisenetv2\"\n",
    "    \n",
    "    CCNET = \"ccnet\"\n",
    "    CGNET = \"cgnet\"\n",
    "    CONTEXTNET = \"contextnet\"\n",
    "    \n",
    "    DANET = \"danet\"\n",
    "    DEEPLABV3 = \"deeplabv3\"\n",
    "    DEEPLABV3_PLUS = \"deeplabv3+\", \"deeplabv3_plus\", \"deeplabv3plus\"\n",
    "    DENSEASPP = \"denseaspp\"\n",
    "    DMNET = \"dmnet\"\n",
    "    DNLNET = \"dnlnet\"\n",
    "    DPT = \"dpt\"\n",
    "    \n",
    "    EMANET = \"emanet\"\n",
    "    ENCNET = \"encnet\"\n",
    "    ERFNET = \"erfnet\"\n",
    "    \n",
    "    FASTFCN = \"fastcn\"\n",
    "    FASTSCNN = \"fastscnn\"\n",
    "    FCN = \"fcn\"\n",
    "    FPENET = \"fpenet\"\n",
    "    FPN = \"fpn\"\n",
    "    \n",
    "    GCNET = \"gcnet\"\n",
    "    \n",
    "    HRNET = \"hrnet\"\n",
    "    \n",
    "    ICNET = \"icnet\"\n",
    "    ISANET = \"isanet\"\n",
    "    \n",
    "    LEDNET = \"lednet\"\n",
    "    LINKNET = \"linknet\"\n",
    "    \n",
    "    MANET = \"manet\"\n",
    "    MASKRCNN = \"maskrcnn\"\n",
    "    MLA = \"mla\"\n",
    "    MOBILENET_V2 = \"movilenet_v2\"\n",
    "    MOBILENET_V3 = \"movilenet_v3\"\n",
    "    \n",
    "    NAIVE = \"naive\"\n",
    "    NONLOCAL_NET = \"nonlocal_net\"\n",
    "    \n",
    "    OCNET = \"ocnet\"\n",
    "    OCRNET = \"ocrnet\"\n",
    "    \n",
    "    PAN = \"pan\"\n",
    "    POINT_REND = \"point_rend\"\n",
    "    PSANET = \"psanet\"\n",
    "    PSPNET = \"pspnet\"\n",
    "    PUP = \"pup\"\n",
    "    \n",
    "    RESNEST = \"resnest\"\n",
    "    \n",
    "    SEGFORMER = \"segformer\"\n",
    "    SEM_FPN = \"sem_fpn\"\n",
    "    SETR = \"setr\"\n",
    "    STDC = \"stdc\"\n",
    "    SWIN = \"swin\"\n",
    "    \n",
    "    TWINS = \"twins\"\n",
    "    \n",
    "    U2NET = \"u2^net\"\n",
    "    UNET = \"unet\"\n",
    "    UNETPLUSPLUS = \"unet++\"\n",
    "    UPERNET = \"upernet\"\n",
    "    \n",
    "    VIT = \"vit\"\n",
    "    VIT_LARGE = \"vit-large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BACKBONE(Enum, metaclass = DirectValueMeta):\n",
    "    \"\"\"\n",
    "    This Enum class defines all the possible backbones that can be used.\n",
    "    \"\"\"\n",
    "    ALEXNET = \"alexnet\"\n",
    "    \n",
    "    BASE_W7 = \"base_patch4_window7\"\n",
    "    BASE_W12 = \"base_patch4_window12\"\n",
    "    \n",
    "    DPN68 = \"dpn68\"\n",
    "    DPN68B = \"dpn68b\"\n",
    "    DPN92 = \"dpn92\"\n",
    "    DPN98 = \"dpn98\"\n",
    "    DPN107 = \"dpn107\"\n",
    "    DPN131 = \"dpn131\"\n",
    "    \n",
    "    DEIT_S16 = \"deit-s16\"\n",
    "    DEIT_B16 = \"deit-b16\"\n",
    "    DENSENET121 = \"densenet121\"\n",
    "    DENSENET169 = \"densenet169\"\n",
    "    DENSENET201 = \"densenet201\"\n",
    "    DENSENET161 = \"densenet161\"\n",
    "    \n",
    "    EFFICIENTNET_B0 = \"efficientnet-b0\"\n",
    "    EFFICIENTNET_B1 = \"efficientnet-b1\"\n",
    "    EFFICIENTNET_B2 = \"efficientnet-b2\"\n",
    "    EFFICIENTNET_B3 = \"efficientnet-b3\"\n",
    "    EFFICIENTNET_B4 = \"efficientnet-b4\"\n",
    "    EFFICIENTNET_B5 = \"efficientnet-b5\"\n",
    "    EFFICIENTNET_B6 = \"efficientnet-b6\"\n",
    "    EFFICIENTNET_B7 = \"efficientnet-b7\"\n",
    "    \n",
    "    FCN = \"fcn\"\n",
    "\n",
    "    HR18 = \"hr18\"\n",
    "    HR18S = \"hr18s\"\n",
    "    HR48 = \"hr48\"\n",
    "    HRNET_W18_SMALL_V1 = \"hrnet_w18_small_v1\", \"hrnet_w18_small_model_v1\"\n",
    "    HRNET_W18_SMALL_V2 = \"hrnet_w18_small_model_v2\"\n",
    "    HRNET_W18 = \"hrnet_w18\"\n",
    "    HRNET_W30 = \"hrnet_w30\"\n",
    "    HRNET_W32 = \"hrnet_w32\"\n",
    "    HRNET_W48 = \"hrnet_w48\"\n",
    "\n",
    "    IN1K_PRE = \"in1k-pre\"\n",
    "    INCEPTIONRESNETV2 = \"inceptionresnetv2\"\n",
    "    INCEPTIONV4 = \"inceptionv4\"\n",
    "\n",
    "    M_V2_D8 = \"m-v2-d8\"\n",
    "    M_V3_D8 = \"m-v3-d8\"\n",
    "    M_V3S_D8 = \"m-v3s-d8\"\n",
    "    MIT_B0 = \"mit-b0\"\n",
    "    MIT_B1 = \"mit-b1\"\n",
    "    MIT_B2 = \"mit-b2\"\n",
    "    MIT_B3 = \"mit-b3\"\n",
    "    MIT_B4 = \"mit-b4\"\n",
    "    MIT_B5 = \"mit-b5\"\n",
    "    MOBILENET_V2 = \"mobilenet_v2\"\n",
    "\n",
    "    NONE = None\n",
    "    NORMAL = \"normal\"\n",
    "\n",
    "    PCPVT_S = \"pcpvt-s\"\n",
    "    PCPVT_B = \"pcpvt-b\"\n",
    "    PCPVT_L = \"pcpvt-l\"\n",
    "    \n",
    "    RESNET18 = \"resnet18\"\n",
    "    RESNET34 = \"resnet34\"\n",
    "    RESNET50 = \"resnet50\", \"r50\"\n",
    "    RESNET101 = \"resnet101\", \"r101\"\n",
    "    RESNET152 = \"resnet152\"\n",
    "    RESNET50C = \"resnet50c\"\n",
    "    RESNET101C = \"resnet101c\"\n",
    "    RESNET152C = \"resnet152c\"\n",
    "    RESNEXT18_32X8D = \"r18-d8\"\n",
    "    RESNEXT18_32X32D = \"r18-d32\"\n",
    "    RESNEXT18B_32X8D = \"r18b-d8\"\n",
    "    RESNEXT50_32X4D = \"resnext50_32x4d\"\n",
    "    RESNEXT50_32X8D = \"r50-d8\"\n",
    "    RESNEXT50_32X32D = \"r50-d32\"\n",
    "    RESNEXT50B_32X8D = \"r50b-d8\"\n",
    "    RESNEXT101_32X8D = \"resnext101_32x8d\", \"r101-d8\"\n",
    "    RESNEXT101B_32X8D = \"r101b-d8\"\n",
    "    RESNEXT101_32X16D = \"resnext101_32x16d\"\n",
    "    RESNEXT101_32X16D_MG124 = \"r101-d16-mg124\"\n",
    "    RESNEXT101_32X32D = \"resnext101_32x32d\", \"r101-d32\"\n",
    "    RESNEXT101_32X48D = \"resnext101_32x48d\"\n",
    "\n",
    "    S5_D16 = \"s5-d16\"\n",
    "    SMALL_W7 = \"small_patch4_window7\"\n",
    "    SVT_S = \"svt-s\"\n",
    "    SVT_B = \"svt-b\"\n",
    "    SVT_L = \"svt-l\"\n",
    "\n",
    "    S101_D8 = \"s101-d8\"\n",
    "    SENET154 = \"senet154\"\n",
    "    SE_RESNET50 = \"se_resnet50\"\n",
    "    SE_RESNET101 = \"se_resnet101\"\n",
    "    SE_RESNET152 = \"se_resnet152\"\n",
    "    SE_RESNEXT50_32X4D = \"se_resnext50_32x4d\"\n",
    "    SE_RESNEXT101_32X4D = \"se_resnext101_32x4d\"\n",
    "    SMALL = \"small\"\n",
    "    SQUEEZENET1_0 = \"squeezenet1_0\"\n",
    "    SQUEEZENET1_1 = \"squeezenet1_1\"\n",
    "    \n",
    "    TINY_W7 = \"tiny_patch4_window7\"\n",
    "    \n",
    "    VGG11 = \"vgg11\"\n",
    "    VGG11_BN = \"vgg11_bn\"\n",
    "    VGG13 = \"vgg13\"\n",
    "    VGG13_BN = \"vgg13_bn\"\n",
    "    VGG16 = \"vgg16\"\n",
    "    VGG16_BN = \"vgg16_bn\"\n",
    "    VGG19 = \"vgg19\"\n",
    "    VGG19_BN = \"vgg19_bn\"\n",
    "    VIT_B16 = \"vit-b16\"\n",
    "    \n",
    "    XCEPTION = \"xception\"\n",
    "    XCEPTION65 = \"xception65\"\n",
    "    XRESNET18 = \"xresnet18\"\n",
    "    XRESNET34 = \"xresnet34\"\n",
    "    XRESNET50 = \"xresnet50\"\n",
    "    XRESNET101 = \"xresnet101\"\n",
    "    XRESNET152 = \"xresnet152\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WEIGHTS(Enum, metaclass = DirectValueMeta):\n",
    "    \"\"\"\n",
    "    This Enum class defines all the possible weights that can be used.\n",
    "    \"\"\"\n",
    "    NONE = None\n",
    "    \n",
    "    ADE20K = \"ade20k\"\n",
    "    \n",
    "    CITYSCAPES = \"cityscapes\"\n",
    "    COCO_STUFF10K = \"coco-stuff10k\"\n",
    "    COCO_STUFF164K = \"coco-stuff164k\"\n",
    "    \n",
    "    DB1 = \"db1\"\n",
    "    DRIVE = \"drive\"\n",
    "    \n",
    "    HRF = \"hrf\"\n",
    "    \n",
    "    IMAGENET = \"imagenet\"\n",
    "    IMAGENETPLUS5K = \"imagenet+5k\"\n",
    "    IMAGENETPLUSBACKGROUND = \"imagenet+background\"\n",
    "    INSTAGRAM = \"instagram\"\n",
    "    \n",
    "    LOVEDA = \"loveda\"\n",
    "    \n",
    "    PASCAL_CONTEXT = \"pascal_context\"\n",
    "    PASCAL_CONTEXT_59 = \"pascal_context_59\"\n",
    "    \n",
    "    STARE = \"stare\"\n",
    "    \n",
    "    VOC12AUG = \"voc12aug\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelManager():\n",
    "    def __init__(self, name, architecture, backbone, weights):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Builds a model.\n",
    "        \n",
    "        Parameters:\n",
    "        name (str): the model's identification.\n",
    "        architecture (str): the model's architecture.\n",
    "        backbone (str): the model's backbone.\n",
    "        weights (str): the model's weights.\n",
    "        \n",
    "        Returns:\n",
    "        m (ModelManager): the built ModelManager (metamodel).\n",
    "        \"\"\"\n",
    "        self.name_ = name\n",
    "        self.architecture_ = architecture\n",
    "        self.backbone_ = backbone\n",
    "        self.weights_ = weights\n",
    "        self.model_ = None\n",
    "        \n",
    "    def is_built(self):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Determines if a model is built or not.\n",
    "        \n",
    "        Parameters:\n",
    "        None.\n",
    "        \n",
    "        Returns:\n",
    "        b (Boolean): if the model is built.\n",
    "        \"\"\"\n",
    "        return self.model_ is not None\n",
    "    \n",
    "    @AOP.excepter(NotImplementedError)\n",
    "    def get_valid_config():\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Returns all the valid constructions dict.\n",
    "        \n",
    "        Parameters:\n",
    "        None.\n",
    "        \n",
    "        Returns\n",
    "        d (dict): the dict of buildables metamodels.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"You can not use this abstract class to get the buildable metamodels.\")\n",
    "    \n",
    "    @AOP.excepter(NotImplementedError)\n",
    "    def is_buildable(architecture, backbone, weights = WEIGHTS.NONE):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Determines if a model can be built using architecture and backbone.\n",
    "        \n",
    "        Parameters:\n",
    "        architecture (str): the model's architecture.\n",
    "        backbone (str): the model's backbone.\n",
    "        weights (str): the model's weights.\n",
    "        \n",
    "        Returns:\n",
    "        finded_build (str, str, str): the combination of hiperparams that can build a model.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"You can not use this abstract class to determine if the model is buildable.\")\n",
    "        \n",
    "    @AOP.excepter(NotImplementedError)\n",
    "    def build(self):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Builds the model.\n",
    "        \n",
    "        Parameters:\n",
    "        None.\n",
    "\n",
    "        Returns:\n",
    "        None.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"You can not use this abstract class to build the model.\")\n",
    "    \n",
    "    @AOP.excepter(NotImplementedError)\n",
    "    def lr_find(self):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Searchs the best learning rate.\n",
    "        \n",
    "        Parameters:\n",
    "        None.\n",
    "        \n",
    "        Returns:\n",
    "        None.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"You can not use this abstract class to suggest the learning rate.\")\n",
    "    \n",
    "    @AOP.excepter(NotImplementedError)\n",
    "    def fit(self, n_epochs = 10):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Trains a model.\n",
    "        \n",
    "        Parameters:\n",
    "        n_epochs (int, 10): the number of epochs.\n",
    "        \n",
    "        Returns:\n",
    "        None.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"You can not use this abstract class to train the model.\")\n",
    "    \n",
    "    @AOP.excepter(NotImplementedError)\n",
    "    def fit_one_cycle(self, n_epochs = 10):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Trains a model with decrease - increase learning rates.\n",
    "        \n",
    "        Parameters:\n",
    "        n_epochs (int, 10): the number of epochs.\n",
    "        \n",
    "        Returns:\n",
    "        None.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"You can not use this abstract class to train the model.\")\n",
    "\n",
    "    @AOP.excepter(NotImplementedError)\n",
    "    def fine_tune(self, n_epochs = 10, n_freeze_epochs = 1):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Trains a model using fine tune technique.\n",
    "        \n",
    "        Parameters:\n",
    "        n_epochs (int, 10): the number of epochs.\n",
    "        n_freeze_epochs (int, 1): the number of freeze epochs.\n",
    "        \n",
    "        Returns:\n",
    "        None.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"You can not use this abstract class to train the model.\")\n",
    "    \n",
    "    @AOP.excepter(NotImplementedError)\n",
    "    def validate(self, test_dls):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Validates a model with the test_dls DataLoader.\n",
    "        \n",
    "        Params:\n",
    "        test_dls (DataLoader): the DataLoader used to validate the model.\n",
    "        \n",
    "        Returns:\n",
    "        None.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"You can not use this abstract class to validate the model.\")\n",
    "    \n",
    "    @AOP.excepter(NotImplementedError)\n",
    "    def save(self, name):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Saves the model in the checkpoints file.\n",
    "        \n",
    "        Parameters:\n",
    "        name (str): the name to give to the model.\n",
    "        \n",
    "        Returns:\n",
    "        The path to the saved model.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"You can not use this abstract class to save the model.\")\n",
    "    \n",
    "    @AOP.excepter(NotImplementedError)\n",
    "    def load(self, model):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Loads a model with a checkpoint file.\n",
    "        \n",
    "        Parameters:\n",
    "        None.\n",
    "        \n",
    "        Returns:\n",
    "        None.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"You can not use this abstract class to load the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelManagerFastai(ModelManager):\n",
    "    def __init__(self, name, architecture, backbone, weights, dls, num_classes = 2, lr = \"best\"):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Defines the training methods for fastai.\n",
    "\n",
    "        Parameters:\n",
    "        name (str): the model's identification.\n",
    "        architecture (str): the model's architecture.\n",
    "        backbone (str): the model's backbone.\n",
    "        dls (DataLoaders): the dataloaders.\n",
    "        num_classes (int, 2): the number of classes.\n",
    "        lr (float | str, \"best\"): the learning rate.\n",
    "        \n",
    "        Returns:\n",
    "        m (ModelManagerFastai): the built ModelManagerFastai.\n",
    "        \"\"\"\n",
    "        # builds the meta model\n",
    "        super().__init__(name, architecture, backbone, weights)\n",
    "        \n",
    "        self.dls_ = dls\n",
    "        self.num_classes_ = num_classes\n",
    "        self.lr_ = lr\n",
    "\n",
    "    @AOP.excepter(NotImplementedError)\n",
    "    def is_buildable(architecture, backbone, weights = WEIGHTS.NONE):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Determines if a model can be built using architecture and backbone.\n",
    "        \n",
    "        Parameters:\n",
    "        architecture (str): the model's architecture.\n",
    "        backbone (str): the model's backbone.\n",
    "        weights (str): the model's weights.\n",
    "        \n",
    "        Returns:\n",
    "        finded_build (str, str, str): the combination of hiperparams that can build a model.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"You can not use this abstract class to determine if the model is buildable.\")\n",
    "        \n",
    "    @AOP.excepter(NotImplementedError)\n",
    "    def build(self):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Builds the model.\n",
    "        \n",
    "        Parameters:\n",
    "        None.\n",
    "\n",
    "        Returns:\n",
    "        None.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"You can not use this abstract class to build the model.\")\n",
    "    \n",
    "    @AOP.excepter(FileNotFoundError)\n",
    "    @AOP.logger(\"Searching the best lr.\", when = \"before\")\n",
    "    @AOP.logger(\"The best lr value is VALUE\")\n",
    "    def lr_find(self):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Searchs the best learning rate.\n",
    "        \n",
    "        Parameters:\n",
    "        None.\n",
    "        \n",
    "        Returns:\n",
    "        None.\n",
    "        \"\"\"\n",
    "        if not self.checkpoints_dir_:\n",
    "            raise FileNotFoundError(\"Learning rate searching needs a defined checkpoints_dir parameter.\")\n",
    "        \n",
    "        # finds the best lr\n",
    "        lr_suggestion = self.model_.lr_find(show_plot = False)\n",
    "        self.lr_ = lr_suggestion.valley\n",
    "        return self.lr_\n",
    "    \n",
    "    def fit(self, n_epochs = 10):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Trains a model.\n",
    "        \n",
    "        Parameters:\n",
    "        n_epochs (int, 10): the number of epochs.\n",
    "        \n",
    "        Returns:\n",
    "        None.\n",
    "        \"\"\"\n",
    "        self.model_.fit(n_epoch = n_epochs, lr = self.lr_)\n",
    "    \n",
    "    def fit_one_cycle(self, n_epochs = 10):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Trains a model with decrease - increase learning rates.\n",
    "        \n",
    "        Parameters:\n",
    "        n_epochs (int, 10): the number of epochs.\n",
    "        \n",
    "        Returns:\n",
    "        None.\n",
    "        \"\"\"\n",
    "        self.model_.fit_one_cycle(n_epoch = n_epochs, lr_max = self.lr_)\n",
    "\n",
    "    def fine_tune(self, n_epochs = 10, n_freeze_epochs = 1):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Abstract method. The way to train a model using fine tune technique.\n",
    "        \n",
    "        Parameters:\n",
    "        n_epochs (int, 10): the number of epochs.\n",
    "        n_freeze_epochs (int, 1): the number of freeze epochs.\n",
    "        \n",
    "        Returns:\n",
    "        None.\n",
    "        \"\"\"\n",
    "        self.model_.fine_tune(epochs = n_epochs - n_freeze_epochs, base_lr = self.lr_, freeze_epochs = n_freeze_epochs)\n",
    "    \n",
    "    @AOP.logger(\"Validating the model.\", when = \"before\")\n",
    "    @AOP.logger(\"The model has been validated. Results: VALUE\")\n",
    "    def validate(self, test_dls):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Validates a model with the test_dls DataLoader.\n",
    "        \n",
    "        Params:\n",
    "        test_dls (DataLoader): the DataLoader used to validate the model.\n",
    "        \n",
    "        Returns:\n",
    "        None.\n",
    "        \"\"\"\n",
    "        self.model_.dls = test_dls\n",
    "        result = self.model_.validate()\n",
    "        self.model_.dls = self.dls_\n",
    "        return result\n",
    "    \n",
    "    @AOP.excepter(RuntimeError, ignore = True)\n",
    "    @AOP.logger(\"The model NAME has been saved.\")\n",
    "    def save(self, name = \"\"):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Saves the model in the checkpoints file.\n",
    "        \n",
    "        Parameters:\n",
    "        name (str): the name to give to the model.\n",
    "        \n",
    "        Returns:\n",
    "        path (str): The path to the saved model.\n",
    "        \"\"\"\n",
    "        if not self.is_built():\n",
    "            raise RuntimeError(\"The model can not be saved because it is not built.\")\n",
    "        else:\n",
    "            self.model_.save(name if name else self.name_)\n",
    "    \n",
    "    @AOP.logger(\"The model NAME has been loaded.\")\n",
    "    def load(self, model):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Loads a model with a checkpoint file.\n",
    "        \n",
    "        Parameters:\n",
    "        None.\n",
    "        \n",
    "        Returns:\n",
    "        None.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"You can not use this abstract class to load the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelManagerSemtorch(ModelManagerFastai):\n",
    "    __valid_config__ = {\n",
    "        ARCHITECTURE.UNET: [\n",
    "            BACKBONE.RESNET18,\n",
    "            BACKBONE.RESNET34,\n",
    "            BACKBONE.RESNET50,\n",
    "            BACKBONE.RESNET101,\n",
    "            BACKBONE.RESNET152,\n",
    "            BACKBONE.XRESNET18,\n",
    "            BACKBONE.XRESNET34,\n",
    "            BACKBONE.XRESNET50,\n",
    "            BACKBONE.XRESNET101,\n",
    "            BACKBONE.XRESNET152,\n",
    "            BACKBONE.SQUEEZENET1_0,\n",
    "            BACKBONE.SQUEEZENET1_1,\n",
    "            BACKBONE.DENSENET121,\n",
    "            BACKBONE.DENSENET169,\n",
    "            BACKBONE.DENSENET201,\n",
    "            BACKBONE.DENSENET161,\n",
    "            BACKBONE.VGG11_BN,\n",
    "            BACKBONE.VGG13_BN,\n",
    "            BACKBONE.VGG16_BN,\n",
    "            BACKBONE.VGG19_BN,\n",
    "            BACKBONE.ALEXNET\n",
    "        ],\n",
    "        ARCHITECTURE.DEEPLABV3_PLUS[0]: [\n",
    "            BACKBONE.RESNET18,\n",
    "            BACKBONE.RESNET34,\n",
    "            BACKBONE.RESNET50,\n",
    "            BACKBONE.RESNET101,\n",
    "            BACKBONE.RESNET152,\n",
    "            BACKBONE.RESNET50C,\n",
    "            BACKBONE.RESNET101C,\n",
    "            BACKBONE.RESNET152C,\n",
    "            BACKBONE.XCEPTION65,\n",
    "            BACKBONE.MOBILENET_V2\n",
    "        ],\n",
    "        ARCHITECTURE.HRNET: [\n",
    "            BACKBONE.HRNET_W18_SMALL_V1[1],\n",
    "            BACKBONE.HRNET_W18_SMALL_V2,\n",
    "            BACKBONE.HRNET_W18,\n",
    "            BACKBONE.HRNET_W30,\n",
    "            BACKBONE.HRNET_W32,\n",
    "            BACKBONE.HRNET_W48\n",
    "        ],\n",
    "        ARCHITECTURE.MASKRCNN: [\n",
    "            BACKBONE.RESNET50\n",
    "        ],\n",
    "        ARCHITECTURE.U2NET: [\n",
    "            BACKBONE.SMALL,\n",
    "            BACKBONE.NORMAL\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    @AOP.excepter(ModelNotBuildable)\n",
    "    @AOP.excepter(TypeError)\n",
    "    def __init__(self, name, architecture, backbone, dls,\n",
    "                 root_dir, checkpoints_dir = \"checkpoint\",\n",
    "                 num_classes = 2, loss_func = None,\n",
    "                 opt_func = fastai.optimizer.Adam, lr = \"best\",\n",
    "                 image_size = None, metrics = [DiceMulti],\n",
    "                 moms = (0.95, 0.85, 0.95), cbs = None):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Builds the model.\n",
    "\n",
    "        Parameters:\n",
    "        name (str): the model's identification.\n",
    "        architecture (str): the model's architecture.\n",
    "        backbone (str): the model's backbone.\n",
    "        dls (DataLoaders): the dataloaders.\n",
    "        root_dir (str): Path-like str. The root directory of the data.\n",
    "        checkpoint (str): Path-like str. The directory where the models are saved.\n",
    "        num_classes (int, 2): the number of classes.\n",
    "        loss_fun (function, None): the loss function for the model.\n",
    "        opt_fun (function, fastai.optimizer.Adam): the optimization function.\n",
    "        lr (float | str, \"best\"): the learning rate.\n",
    "        image_size (int, None): Mandatory for MaskRCNN. It indicates the desired size of the image.\n",
    "        metrics (list[function]): list of metrics.\n",
    "        checkpoints_dir (str, None): the path where the checkpoints are saved. Mandatory if lr_find is used.\n",
    "        moms (tuple(float), (0.95, 0.85, 0.95)): tuple of different momentums.\n",
    "        cbs (list[function], None): list of callbacks.\n",
    "        \n",
    "        Returns:\n",
    "        m (ModelManager): the built ModelManager (metamodel).\n",
    "        \"\"\"\n",
    "        # builds the meta model\n",
    "        super().__init__(name, architecture, backbone, WEIGHTS.NONE, dls, num_classes, lr)\n",
    "\n",
    "        # specific parameters for semtorch\n",
    "        self.root_dir_ = root_dir\n",
    "        self.checkpoints_dir_ = checkpoints_dir\n",
    "        self.loss_func_ = loss_func\n",
    "        self.opt_func_ = opt_func\n",
    "        self.image_size_ = image_size\n",
    "        self.metrics_ = metrics\n",
    "        self.moms_ = moms\n",
    "        self.cbs_ = cbs + [CSVLogger] if cbs else [CSVLogger]\n",
    "\n",
    "        # checks the common mistake spots\n",
    "        if not ModelManagerSemtorch.is_buildable(architecture, backbone):\n",
    "            raise ModelNotBuildable(\"The model is not buildable.\")\n",
    "\n",
    "        elif self.architecture_ == \"maskrcnn\" and self.image_size_ is None:\n",
    "            raise TypeError(\"image_size parameter is mandatory for MaskRCNN architecture.\")\n",
    "\n",
    "        # builds the model\n",
    "        self.build()\n",
    "\n",
    "        # searchs the best lr value\n",
    "        if self.lr_ == \"best\":\n",
    "            self.lr_find()\n",
    "    \n",
    "    def get_valid_config():\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Returns all the valid constructions dict.\n",
    "        \n",
    "        Parameters:\n",
    "        None.\n",
    "        \n",
    "        Returns\n",
    "        d (dict): the dict of buildables metamodels.\n",
    "        \"\"\"\n",
    "        return ModelManagerSemtorch.__valid_config__\n",
    "    \n",
    "    def is_buildable(architecture, backbone, weights = WEIGHTS.NONE):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Determines if a model can be built using architecture and backbone.\n",
    "        \n",
    "        Parameters:\n",
    "        architecture (str | list): the model's architecture.\n",
    "        backbone (str | list): the model's backbone.\n",
    "        weights (str | list): the model's weights.\n",
    "        \n",
    "        Returns:\n",
    "        finded_build (str, str, str): the combination of hiperparams that can build a model.\n",
    "        \"\"\"\n",
    "        if type(architecture) is str:\n",
    "            if architecture in ModelManagerSemtorch.__valid_config__:\n",
    "                if type(backbone) is str:\n",
    "                    if backbone in ModelManagerSemtorch.__valid_config__[architecture]:\n",
    "                        return (architecture, backbone, weights)\n",
    "                elif type(backbone) is tuple:\n",
    "                    return coalesce([ModelManagerSemtorch.is_buildable(architecture, _backbone) for _backbone in backbone])\n",
    "\n",
    "        elif type(architecture) is tuple:\n",
    "            return coalesce([ModelManagerSemtorch.is_buildable(_architecture, backbone) for _architecture in architecture])\n",
    "        \n",
    "    def build(self):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Builds the model.\n",
    "        \n",
    "        Parameters:\n",
    "        None.\n",
    "        \n",
    "        Returns:\n",
    "        None.\n",
    "        \"\"\"\n",
    "        model = semtorch.get_segmentation_learner(dls = self.dls_, number_classes = self.num_classes_,\n",
    "                                                  segmentation_type = \"Semantic Segmentation\",\n",
    "                                                  architecture_name = self.architecture_, backbone_name = self.backbone_,\n",
    "                                                  loss_func = self.loss_func_, opt_func = self.opt_func_,\n",
    "                                                  lr = self.lr_, splitter = trainable_params,\n",
    "                                                  cbs = self.cbs_, pretrained = True,\n",
    "                                                  normalize = True, image_size = self.image_size_,\n",
    "                                                  metrics = self.metrics_, path = self.root_dir_,\n",
    "                                                  model_dir = self.checkpoints_dir_, wd = None,\n",
    "                                                  wd_bn_bias = False, train_bn = True,\n",
    "                                                  moms = self.moms_).to_fp16()\n",
    "        \n",
    "        self.model_ = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelManagerSMP(ModelManagerFastai):\n",
    "    __architectures__ = [\n",
    "        ARCHITECTURE.UNET,\n",
    "        ARCHITECTURE.LINKNET,\n",
    "        ARCHITECTURE.FPN,\n",
    "        ARCHITECTURE.PSPNET,\n",
    "        ARCHITECTURE.PAN\n",
    "    ]\n",
    "    __backbones__ = {\n",
    "          BACKBONE.RESNET18: [WEIGHTS.IMAGENET],\n",
    "          BACKBONE.RESNET34: [WEIGHTS.IMAGENET],\n",
    "          BACKBONE.RESNET50: [WEIGHTS.IMAGENET],\n",
    "          BACKBONE.RESNET101: [WEIGHTS.IMAGENET],\n",
    "          BACKBONE.RESNET152: [WEIGHTS.IMAGENET],\n",
    "          BACKBONE.RESNEXT50_32X4D: [WEIGHTS.IMAGENET],\n",
    "          BACKBONE.RESNEXT101_32X8D: [WEIGHTS.IMAGENET, WEIGHTS.INSTAGRAM],\n",
    "          BACKBONE.RESNEXT101_32X16D: [WEIGHTS.INSTAGRAM],\n",
    "          BACKBONE.RESNEXT101_32X32D: [WEIGHTS.INSTAGRAM],\n",
    "          BACKBONE.RESNEXT101_32X48D: [WEIGHTS.INSTAGRAM],\n",
    "          BACKBONE.DPN68: [WEIGHTS.IMAGENET],\n",
    "          BACKBONE.DPN68B: [WEIGHTS.IMAGENETPLUS5K],\n",
    "          BACKBONE.DPN92: [WEIGHTS.IMAGENETPLUS5K],\n",
    "          BACKBONE.DPN98: [WEIGHTS.IMAGENET],\n",
    "          BACKBONE.DPN107: [WEIGHTS.IMAGENETPLUS5K],\n",
    "          BACKBONE.DPN131: [WEIGHTS.IMAGENET],\n",
    "          BACKBONE.VGG11: [WEIGHTS.IMAGENET],\n",
    "          BACKBONE.VGG11_BN: [WEIGHTS.IMAGENET],\n",
    "          BACKBONE.VGG13: [WEIGHTS.IMAGENET],\n",
    "          BACKBONE.VGG13_BN: [WEIGHTS.IMAGENET],\n",
    "          BACKBONE.VGG16: [WEIGHTS.IMAGENET],\n",
    "          BACKBONE.VGG16_BN: [WEIGHTS.IMAGENET],\n",
    "          BACKBONE.VGG19: [WEIGHTS.IMAGENET],\n",
    "          BACKBONE.VGG19_BN: [WEIGHTS.IMAGENET],\n",
    "          BACKBONE.SENET154: [WEIGHTS.IMAGENET],\n",
    "          BACKBONE.SE_RESNET50: [WEIGHTS.IMAGENET],\n",
    "          BACKBONE.SE_RESNET101: [WEIGHTS.IMAGENET],\n",
    "          BACKBONE.SE_RESNET152: [WEIGHTS.IMAGENET],\n",
    "          BACKBONE.SE_RESNEXT50_32X4D: [WEIGHTS.IMAGENET],\n",
    "          BACKBONE.SE_RESNEXT101_32X4D: [WEIGHTS.IMAGENET],\n",
    "          BACKBONE.DENSENET121: [WEIGHTS.IMAGENET],\n",
    "          BACKBONE.DENSENET161: [WEIGHTS.IMAGENET],\n",
    "          BACKBONE.DENSENET169: [WEIGHTS.IMAGENET],\n",
    "          BACKBONE.DENSENET201: [WEIGHTS.IMAGENET],\n",
    "          BACKBONE.INCEPTIONRESNETV2: [WEIGHTS.IMAGENET, WEIGHTS.IMAGENETPLUSBACKGROUND],\n",
    "          BACKBONE.INCEPTIONV4: [WEIGHTS.IMAGENET, WEIGHTS.IMAGENETPLUSBACKGROUND],\n",
    "          BACKBONE.EFFICIENTNET_B0: [WEIGHTS.IMAGENET],\n",
    "          BACKBONE.EFFICIENTNET_B1: [WEIGHTS.IMAGENET],\n",
    "          BACKBONE.EFFICIENTNET_B2: [WEIGHTS.IMAGENET],\n",
    "          BACKBONE.EFFICIENTNET_B3: [WEIGHTS.IMAGENET],\n",
    "          BACKBONE.EFFICIENTNET_B4: [WEIGHTS.IMAGENET],\n",
    "          BACKBONE.EFFICIENTNET_B5: [WEIGHTS.IMAGENET],\n",
    "          BACKBONE.EFFICIENTNET_B6: [WEIGHTS.IMAGENET],\n",
    "          BACKBONE.EFFICIENTNET_B7: [WEIGHTS.IMAGENET],\n",
    "          BACKBONE.MOBILENET_V2: [WEIGHTS.IMAGENET],\n",
    "          BACKBONE.XCEPTION: [WEIGHTS.IMAGENET]\n",
    "    }\n",
    "    \n",
    "    @AOP.excepter(ModelNotBuildable)\n",
    "    @AOP.excepter(TypeError)\n",
    "    def __init__(self, name, architecture, backbone, weights, dls,\n",
    "                 root_dir = \"\", checkpoints_dir = \"checkpoint\",\n",
    "                 num_classes = 1, loss_func = None,\n",
    "                 opt_func = fastai.optimizer.Adam, lr = \"best\",\n",
    "                 metrics = [DiceMulti], moms = (0.95, 0.85, 0.95),\n",
    "                 cbs = None\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Builds the model.\n",
    "\n",
    "        Parameters:\n",
    "        name (str): the model's identification.\n",
    "        architecture (str): the model's architecture.\n",
    "        backbone (str): the model's backbone.\n",
    "        weights (str, \"\"): the model's weights.\n",
    "        dls (DataLoaders, None): the dataloaders.\n",
    "        root_dir (str, \"\"): Path-like str. The root directory of the data.\n",
    "        checkpoints_dir (str, \"checkpoint\"): Path-like str. The directory where the models are saved.\n",
    "        num_classes (int, 1): the number of classes.\n",
    "        loss_fun (function, None): the loss function for the model.\n",
    "        opt_fun (function, fastai.optimizer.Adam): the optimization function.\n",
    "        lr (float | str, \"best\"): the learning rate.\n",
    "        metrics (list[function]): list of metrics.\n",
    "        moms (tuple(float), (0.95, 0.85, 0.95)): tuple of different momentums.\n",
    "        cbs (list[function], None): list of callbacks.\n",
    "        \n",
    "        Returns:\n",
    "        m (ModelManager): the built ModelManager (metamodel).\n",
    "        \"\"\"\n",
    "        # builds the meta model\n",
    "        super().__init__(name, architecture, backbone, weights, dls, num_classes, lr)\n",
    "        \n",
    "        # specific parameters for semtorch\n",
    "        self.root_dir_ = root_dir\n",
    "        self.checkpoints_dir_ = checkpoints_dir\n",
    "        self.loss_func_ = loss_func\n",
    "        self.opt_func_ = opt_func\n",
    "        self.metrics_ = metrics\n",
    "        self.moms_ = moms\n",
    "        self.cbs_ = cbs + [CSVLogger] if cbs else [CSVLogger]\n",
    "\n",
    "        # checks the common mistake spots\n",
    "        if not ModelManagerSMP.is_buildable(architecture, backbone, weights):\n",
    "            raise ModelNotBuildable(\"The model is not buildable.\")\n",
    "\n",
    "        # builds the model\n",
    "        self.build()\n",
    "\n",
    "        # searchs the best lr value\n",
    "        if self.lr_ == \"best\":\n",
    "            self.lr_find()\n",
    "    \n",
    "    def get_valid_config():\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Returns all the valid constructions dict.\n",
    "        \n",
    "        Parameters:\n",
    "        None.\n",
    "        \n",
    "        Returns\n",
    "        d (dict): the dict of buildables metamodels.\n",
    "        \"\"\"\n",
    "        return {architecture: ModelManagerSMP.__backbones__ for architecture in ModelManagerSMP.__architectures__}\n",
    "\n",
    "    def is_buildable(architecture, backbone, weights = WEIGHTS.NONE):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Determines if a model can be built using architecture and backbone.\n",
    "\n",
    "        Parameters:\n",
    "        architecture (str | list): the model's architecture.\n",
    "        backbone (str | list): the model's backbone.\n",
    "        weights (str | list): the model's weights.\n",
    "\n",
    "        Returns:\n",
    "        finded_build (str, str, str): the combination of hiperparams that can build a model.\n",
    "        \"\"\"\n",
    "        valid_config = ModelManagerSMP.get_valid_config()\n",
    "        if type(architecture) is str:\n",
    "            if architecture in valid_config:\n",
    "                _architecture = valid_config[architecture]\n",
    "                if type(backbone) is str:\n",
    "                    if backbone in _architecture:\n",
    "                        if weights == WEIGHTS.NONE or weights in _architecture[backbone]:\n",
    "                            return (architecture, backbone, weights)\n",
    "                elif type(backbone) is tuple:\n",
    "                    return coalesce([ModelManagerSMP.is_buildable(architecture, _backbone, weights) for _backbone in backbone])\n",
    "\n",
    "        elif type(architecture) is tuple:\n",
    "            return coalesce([ModelManagerSMP.is_buildable(_architecture, backbone, weights) for _architecture in architecture])\n",
    "    \n",
    "    def build(self):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Builds the model.\n",
    "        \n",
    "        Parameters:\n",
    "        None.\n",
    "        \n",
    "        Returns:\n",
    "        None.\n",
    "        \"\"\"\n",
    "        encoder = smp.create_model(self.architecture_, self.backbone_, self.weights_, classes = self.num_classes_)\n",
    "        model = fastai.basics.Learner(self.dls_, encoder,\n",
    "                                      loss_func = self.loss_func_, opt_func = self.opt_func_,\n",
    "                                      lr = self.lr_, splitter = trainable_params,\n",
    "                                      cbs = self.cbs_, metrics = self.metrics_,\n",
    "                                      path = self.root_dir_, model_dir = self.checkpoints_dir_,\n",
    "                                      wd = None, wd_bn_bias = False,\n",
    "                                      train_bn = True, moms = self.moms_).to_fp16()\n",
    "        self.model_ = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelManagerSegmenTron(ModelManagerFastai):\n",
    "    __valid_config__ = {\n",
    "        ARCHITECTURE.BISENET: [\n",
    "            BACKBONE.RESNET18,\n",
    "            BACKBONE.RESNET34\n",
    "        ],\n",
    "        ARCHITECTURE.CGNET: [\n",
    "            BACKBONE.NONE\n",
    "        ],\n",
    "        ARCHITECTURE.CONTEXTNET: [\n",
    "            BACKBONE.NONE\n",
    "        ],\n",
    "        ARCHITECTURE.CGNET: [\n",
    "            BACKBONE.NONE\n",
    "        ],\n",
    "        ARCHITECTURE.CONTEXTNET: [\n",
    "            BACKBONE.NONE\n",
    "        ],\n",
    "        ARCHITECTURE.DEEPLABV3_PLUS[1]: [\n",
    "            BACKBONE.MOBILENET_V2,\n",
    "            BACKBONE.RESNET18,\n",
    "            BACKBONE.RESNET34,\n",
    "            BACKBONE.RESNET50,\n",
    "            BACKBONE.RESNET101,\n",
    "            BACKBONE.RESNET152,\n",
    "            BACKBONE.RESNET50C,\n",
    "            BACKBONE.RESNET101C,\n",
    "            BACKBONE.RESNET152C,\n",
    "            BACKBONE.XCEPTION65\n",
    "        ],\n",
    "        ARCHITECTURE.DENSEASPP: [\n",
    "            BACKBONE.MOBILENET_V2,\n",
    "            BACKBONE.RESNET18,\n",
    "            BACKBONE.RESNET34,\n",
    "            BACKBONE.RESNET50,\n",
    "            BACKBONE.RESNET101,\n",
    "            BACKBONE.RESNET152,\n",
    "            BACKBONE.RESNET50C,\n",
    "            BACKBONE.RESNET101C,\n",
    "            BACKBONE.RESNET152C\n",
    "        ],\n",
    "        ARCHITECTURE.FCN: [\n",
    "            BACKBONE.RESNET50,\n",
    "            BACKBONE.RESNET101,\n",
    "            BACKBONE.RESNET152,\n",
    "            BACKBONE.RESNET50C,\n",
    "            BACKBONE.RESNET101C,\n",
    "            BACKBONE.RESNET152C,\n",
    "            BACKBONE.XCEPTION65\n",
    "        ],\n",
    "        ARCHITECTURE.FPENET: [\n",
    "            BACKBONE.NONE\n",
    "        ],\n",
    "        ARCHITECTURE.HRNET: [\n",
    "            BACKBONE.HRNET_W18_SMALL_V1[0]\n",
    "        ],\n",
    "        ARCHITECTURE.LEDNET: [\n",
    "            BACKBONE.NONE\n",
    "        ],\n",
    "        ARCHITECTURE.OCNET: [\n",
    "            BACKBONE.RESNET50,\n",
    "            BACKBONE.RESNET101,\n",
    "            BACKBONE.RESNET152,\n",
    "            BACKBONE.RESNET50C,\n",
    "            BACKBONE.RESNET101C,\n",
    "            BACKBONE.RESNET152C,\n",
    "            BACKBONE.XCEPTION65\n",
    "        ],\n",
    "        ARCHITECTURE.PSPNET: [\n",
    "            BACKBONE.RESNET50,\n",
    "            BACKBONE.RESNET101,\n",
    "            BACKBONE.RESNET152,\n",
    "            BACKBONE.RESNET50C,\n",
    "            BACKBONE.RESNET101C,\n",
    "            BACKBONE.RESNET152C,\n",
    "            BACKBONE.XCEPTION65\n",
    "        ],\n",
    "        ARCHITECTURE.UNET: [\n",
    "            BACKBONE.NONE\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    @AOP.excepter(ModelNotBuildable)\n",
    "    @AOP.excepter(TypeError)\n",
    "    def __init__(self, name, architecture, backbone, dls,\n",
    "                 root_dir = \"\", checkpoints_dir = \"checkpoint\",\n",
    "                 num_classes = 1, loss_func = None,\n",
    "                 opt_func = fastai.optimizer.Adam, lr = \"best\",\n",
    "                 metrics = [DiceMulti], moms = (0.95, 0.85, 0.95),\n",
    "                 cbs = None\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Builds the model.\n",
    "\n",
    "        Parameters:\n",
    "        name (str): the model's identification.\n",
    "        architecture (str): the model's architecture.\n",
    "        backbone (str): the model's backbone.\n",
    "        dls (DataLoaders, None): the dataloaders.\n",
    "        root_dir (str, \"\"): Path-like str. The root directory of the data.\n",
    "        checkpoints_dir (str, \"checkpoint\"): Path-like str. The directory where the models are saved.\n",
    "        num_classes (int, 1): the number of classes.\n",
    "        loss_fun (function, None): the loss function for the model.\n",
    "        opt_fun (function, fastai.optimizer.Adam): the optimization function.\n",
    "        lr (float | str, \"best\"): the learning rate.\n",
    "        metrics (list[function]): list of metrics.\n",
    "        moms (tuple(float), (0.95, 0.85, 0.95)): tuple of different momentums.\n",
    "        cbs (list[function], None): list of callbacks.\n",
    "        \n",
    "        Returns:\n",
    "        m (ModelManager): the built ModelManager (metamodel).\n",
    "        \"\"\"\n",
    "        # builds the meta model\n",
    "        super().__init__(name, architecture, backbone, WEIGHTS.NONE, dls, num_classes, lr)\n",
    "        \n",
    "        # specific parameters for semtorch\n",
    "        self.root_dir_ = root_dir\n",
    "        self.checkpoints_dir_ = checkpoints_dir\n",
    "        self.loss_func_ = loss_func\n",
    "        self.opt_func_ = opt_func\n",
    "        self.metrics_ = metrics\n",
    "        self.moms_ = moms\n",
    "        self.cbs_ = cbs + [CSVLogger] if cbs else [CSVLogger]\n",
    "\n",
    "        # checks the common mistake spots\n",
    "        if not ModelManagerSegmenTron.is_buildable(architecture, backbone, WEIGHTS.NONE):\n",
    "            raise ModelNotBuildable(\"The model is not buildable.\")\n",
    "\n",
    "        # builds the model\n",
    "        self.build()\n",
    "\n",
    "        # searchs the best lr value\n",
    "        if self.lr_ == \"best\":\n",
    "            self.lr_find()\n",
    "    \n",
    "    def get_valid_config():\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Returns all the valid constructions dict.\n",
    "        \n",
    "        Parameters:\n",
    "        None.\n",
    "        \n",
    "        Returns\n",
    "        d (dict): the dict of buildables metamodels.\n",
    "        \"\"\"\n",
    "        return ModelManagerSegmenTron.__valid_config__\n",
    "\n",
    "    def is_buildable(architecture, backbone, weights = WEIGHTS.NONE):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Determines if a model can be built using architecture and backbone.\n",
    "        \n",
    "        Parameters:\n",
    "        architecture (str): the model's architecture.\n",
    "        backbone (str): the model's backbone.\n",
    "        weights (str): the model's weights.\n",
    "        \n",
    "        Returns:\n",
    "        finded_build (str, str, str): the combination of hiperparams that can build a model.\n",
    "        \"\"\"\n",
    "        if type(architecture) is str:\n",
    "            if architecture in ModelManagerSegmenTron.__valid_config__:\n",
    "                if type(backbone) is str or type(backbone) is None:\n",
    "                    if backbone in ModelManagerSegmenTron.__valid_config__[architecture]:\n",
    "                        return (architecture, backbone, weights)\n",
    "                elif type(backbone) is str:\n",
    "                    return coalesce([ModelManagerSegmenTron.is_buildable(architecture, _backbone) for _backbone in backbone])\n",
    "\n",
    "        elif type(architecture) is tuple:\n",
    "            return coalesce([ModelManagerSegmenTron.is_buildable(_architecture, backbone) for _architecture in architecture])\n",
    "        \n",
    "    def build(self):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Builds the model.\n",
    "        \n",
    "        Parameters:\n",
    "        None.\n",
    "        \n",
    "        Returns:\n",
    "        None.\n",
    "        \"\"\"\n",
    "        if self.architecture_ == \"bisenet\":\n",
    "            encoder = segmentron.BiSeNet(nclass = self.num_classes_, backbone_name = self.backbone_)\n",
    "        elif self.architecture_ == \"cgnet\":\n",
    "            encoder = segmentron.CGNet(nclass = self.num_classes_)\n",
    "        elif self.architecture_ == \"contextnet\":\n",
    "            encoder = segmentron.ContextNet(nclass = self.num_classes_)\n",
    "        elif self.architecture_ == \"deeplabv3_plus\":\n",
    "            encoder = segmentron.DeepLabV3Plus(nclass = self.num_classes_, backbone_name=self.backbone_)\n",
    "        elif self.architecture_ == \"denseaspp\":\n",
    "            encoder = segmentron.DenseASPP(nclass = self.num_classes_, backbone_name=self.backbone_)\n",
    "        elif self.architecture_ == \"fcn\":\n",
    "            encoder = segmentron.FCN(nclass = self.num_classes_, backbone_name=self.backbone_)\n",
    "        elif self.architecture_ == \"fpenet\":\n",
    "            encoder = segmentron.FPENet(nclass = self.num_classes_)\n",
    "        elif self.architecture_ == \"hrnet\":\n",
    "            encoder = segmentron.HRNet(nclass = self.num_classes_, backbone_name=self.backbone_)\n",
    "        elif self.architecture_ == \"lednet\":\n",
    "            encoder = segmentron.LEDNet(nclass = self.num_classes_)\n",
    "        elif self.architecture_ == \"ocnet\":\n",
    "            encoder = segmentron.OCNet(nclass = self.num_classes_, backbone_name=self.backbone_)\n",
    "        elif self.architecture_ == \"pspnet\":\n",
    "            encoder = segmentron.PSPNet(nclass = self.num_classes_, backbone_name=self.backbone_)\n",
    "        elif self.architecture_ == \"unet\":\n",
    "            encoder = segmentron.UNet(nclass = self.num_classes_)\n",
    "        \n",
    "        if encoder:\n",
    "            model = fastai.basics.Learner(self.dls_, encoder,\n",
    "                                          loss_func = self.loss_func_, opt_func = self.opt_func_,\n",
    "                                          lr = self.lr_, splitter = trainable_params,\n",
    "                                          cbs = self.cbs_, metrics = self.metrics_,\n",
    "                                          path = self.root_dir_, model_dir = self.checkpoints_dir_,\n",
    "                                          wd = None, wd_bn_bias = False,\n",
    "                                          train_bn = True, moms = self.moms_).to_fp16()\n",
    "            self.model_ = model\n",
    "        else:\n",
    "            self.model_ = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelManagerMMSegmentation(ModelManager):\n",
    "    def __init__(self, name, architecture, backbone, weights,\n",
    "                 root_dir, batch_size, num_classes,\n",
    "                 train_pipeline, test_pipeline,\n",
    "                 data_split, gpu_device\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Builds a model.\n",
    "        \n",
    "        Parameters:\n",
    "        name (str): the name of the dataset.\n",
    "        architecture (str): the model's architecture and backbone.\n",
    "        backbone (str): ignored. Just for backwards compatibility.\n",
    "        weights (str): the model's weights.\n",
    "        root_dir (str): the root dir for the dataset.\n",
    "        batch_size (int): the number of images shown to the model at the same time.\n",
    "        num_classes (int): the number of classes to detect.\n",
    "        train_pipeline (list[dict]): the train pipeline.\n",
    "        test_pipeline (list[dict]): the test pipeline.\n",
    "        data_split (dict): the data split for the fold that will be trained.\n",
    "        gpu_device (int): the gpu that will be used to train the model.\n",
    "        \n",
    "        Returns:\n",
    "        m (ModelManager): the built ModelManager (metamodel).\n",
    "        \"\"\"\n",
    "        super().__init__(name, architecture, backbone, weights)\n",
    "        self.cfg_ = None\n",
    "        self.mode_ = \"train\"\n",
    "        self.root_dir_ = root_dir\n",
    "        self.batch_size_ = batch_size\n",
    "        self.num_classes_ = num_classes\n",
    "        self.train_pipeline_ = train_pipeline\n",
    "        self.test_pipeline_ = test_pipeline\n",
    "        self.data_split_ = data_split\n",
    "        self.gpu_device_ = gpu_device\n",
    "        \n",
    "        # builds the model\n",
    "        self.build()\n",
    "        \n",
    "    def is_built(self):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Determines if a model is built or not.\n",
    "        \n",
    "        Parameters:\n",
    "        None.\n",
    "        \n",
    "        Returns:\n",
    "        b (Boolean): if the model is built.\n",
    "        \"\"\"\n",
    "        return self.model_ is not None\n",
    "    \n",
    "    @AOP.excepter(NotImplementedError)\n",
    "    def get_valid_config():\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Returns all the valid constructions dict.\n",
    "        \n",
    "        Parameters:\n",
    "        None.\n",
    "        \n",
    "        Returns\n",
    "        d (dict): the dict of buildables metamodels.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"You can find all the configurations on 'configs' directory. They are used dynamically.\")\n",
    "\n",
    "    def __is_buildable__(architecture, backbone, weights, data):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Inmersion for is_buildable function to optimize file readings.\n",
    "        \n",
    "        Parameters:\n",
    "        architecture (str): the model's architecture.\n",
    "        backbone (str): the model's backbone.\n",
    "        weights (str): the model's weights.\n",
    "        data (str | None): the data inside the config file.\n",
    "        \n",
    "        Returns:\n",
    "        finded_build (str, str, str): the combination of hiperparams that can build a model.\n",
    "        \"\"\"\n",
    "        if not data:\n",
    "            return None\n",
    "\n",
    "        for model in data[\"Models\"]:\n",
    "            _config = model[\"Name\"]\n",
    "            _weights = model[\"Weights\"]\n",
    "            if type(architecture) is str:\n",
    "                if type(backbone) is str:\n",
    "                    if re.match(f\".*_{backbone}.*{weights}.py\", _config):\n",
    "                        return (_config, None, _weights)\n",
    "                elif type(backbone) is tuple:\n",
    "                    return coalesce([ModelManagerMMSegmentation.__is_buildable__(architecture, _backbone, weights, data) for _backbone in backbone])\n",
    "                \n",
    "            elif type(architecture) is tuple:\n",
    "                return coalesce([ModelManagerMMSegmentation.__is_buildable__(_architecture, backbone, weights, data) for _architecture in architecture])\n",
    "        \n",
    "    def is_buildable(architecture, backbone = BACKBONE.NONE, weights = WEIGHTS.NONE):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Determines if a model can be built using architecture and backbone.\n",
    "        \n",
    "        Parameters:\n",
    "        architecture (str): the model's architecture.\n",
    "        backbone (str): the model's backbone.\n",
    "        weights (str): the model's weights.\n",
    "        \n",
    "        Returns:\n",
    "        finded_build (str, str, str): the combination of hiperparams that can build a model.\n",
    "        \"\"\"\n",
    "        # we need a string-like backbone and weights, not None\n",
    "        backbone = backbone if backbone else \"\"\n",
    "        weights = weights if weights else \"\"\n",
    "\n",
    "        if type(architecture) is str:\n",
    "            architecture = [architecture]\n",
    "        \n",
    "        datas = []\n",
    "        for _architecture in architecture:\n",
    "            configuration_file = osp.join(\"configs\", _architecture, f\"{_architecture}.yml\")\n",
    "            if osp.isfile(configuration_file):\n",
    "                with open(configuration_file) as f:\n",
    "                    datas.append(yaml.load(f, Loader = yaml.FullLoader))\n",
    "            else:\n",
    "                datas.append(None)\n",
    "    \n",
    "        return coalesce([ModelManagerMMSegmentation.__is_buildable__(_architecture, backbone, weights, _data) for _architecture, _data in zip(architecture, datas)])\n",
    "\n",
    "    @AOP.excepter(AttributeError)\n",
    "    def build(self):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Builds the model.\n",
    "        \n",
    "        Parameters:\n",
    "        None.\n",
    "\n",
    "        Returns:\n",
    "        None.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            cfg = Config.fromfile(self.architecture_)\n",
    "\n",
    "            # metadata params\n",
    "            cfg.norm_cfg = dict(type = \"BN\", requires_grad = True)\n",
    "            cfg.model.backbone.norm_cfg = cfg.norm_cfg\n",
    "            cfg.model.decode_head.norm_cfg = cfg.norm_cfg\n",
    "            cfg.model.auxiliary_head.norm_cfg = cfg.norm_cfg\n",
    "            cfg.model.decode_head.num_classes = self.num_classes_\n",
    "            cfg.model.auxiliary_head.num_classes = self.num_classes_\n",
    "            cfg.dataset_type = self.name_\n",
    "            cfg.data_root = self.root_dir_\n",
    "            cfg.data.samples_per_gpu = self.batch_size_\n",
    "            cfg.data.workers_per_gpu = 2\n",
    "\n",
    "            # transform pipelines\n",
    "            cfg.img_norm_cfg = dict(mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
    "            cfg.crop_size = (256, 256)\n",
    "            cfg.train_pipeline = self.train_pipeline_\n",
    "            cfg.test_pipeline = self.test_pipeline_\n",
    "\n",
    "            # training params\n",
    "            cfg.data.train.type = cfg.dataset_type\n",
    "            cfg.data.train.data_root = cfg.data_root\n",
    "            cfg.data.train.img_dir = \"images\"\n",
    "            cfg.data.train.ann_dir = \"masks\"\n",
    "            cfg.data.train.pipeline = cfg.train_pipeline\n",
    "            cfg.data.train.split = osp.join(\"splits\", self.data_split_[\"train\"])\n",
    "\n",
    "            # validation params\n",
    "            cfg.data.val.type = cfg.dataset_type\n",
    "            cfg.data.val.data_root = cfg.data_root\n",
    "            cfg.data.val.img_dir = \"images\"\n",
    "            cfg.data.val.ann_dir = \"masks\"\n",
    "            cfg.data.val.pipeline = cfg.test_pipeline\n",
    "            cfg.data.val.split = osp.join(\"splits\", self.data_split_[\"val\"])\n",
    "\n",
    "            # testing params\n",
    "            cfg.data.test.type = cfg.dataset_type\n",
    "            cfg.data.test.data_root = cfg.data_root\n",
    "            cfg.data.test.img_dir = \"images\"\n",
    "            cfg.data.test.ann_dir = \"masks\"\n",
    "            cfg.data.test.pipeline = cfg.test_pipeline\n",
    "            cfg.data.test.split = osp.join(\"splits\", self.data_split_[\"test\"])\n",
    "\n",
    "            # Set up working dir to save files and logs.\n",
    "            cfg.work_dir = self.root_dir_\n",
    "            cfg.log_config.interval = 1\n",
    "            cfg.log_config.by_epoch = True\n",
    "            cfg.log_config.hooks = [\n",
    "                dict(type='TextLoggerHook', by_epoch = True),\n",
    "            ] # file log\n",
    "\n",
    "            # gpus used\n",
    "            cfg.seed = None\n",
    "            cfg.gpu_ids = [self.gpu_device_]\n",
    "\n",
    "            # training mode\n",
    "            cfg.runner.type = \"EpochBasedRunner\" # by default it uses IterBasedRunner\n",
    "            del cfg.runner.max_iters\n",
    "            cfg.checkpoint_config.by_epoch = True\n",
    "            cfg.checkpoint_config.interval = 1\n",
    "            cfg.checkpoint_config.max_keep_ckpts = 1\n",
    "\n",
    "            # evaluation\n",
    "            cfg.evaluation.interval = 1\n",
    "            cfg.evaluation.by_epoch = True\n",
    "\n",
    "            # saves the new cfg\n",
    "            self.model_ = build_segmentor(cfg.model, train_cfg = cfg.get('train_cfg'), test_cfg = cfg.get('test_cfg'))\n",
    "            self.cfg_ = cfg\n",
    "        except AttributeError as e:\n",
    "            raise AttributeError(\"Some configuration settings for this model are not implemented yet.\")\n",
    "\n",
    "    @AOP.excepter(NotImplementedError)\n",
    "    def lr_find(self):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Searchs the best learning rate.\n",
    "        \n",
    "        Parameters:\n",
    "        None.\n",
    "        \n",
    "        Returns:\n",
    "        None.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Those models get the best learning rate by default.\")\n",
    "    \n",
    "    @AOP.excepter(NotImplementedError)\n",
    "    def fit(self, n_epochs = 10):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Trains a model.\n",
    "        \n",
    "        Parameters:\n",
    "        n_epochs (int, 10): the number of epochs.\n",
    "        \n",
    "        Returns:\n",
    "        None.\n",
    "        \"\"\"\n",
    "        # the dataset\n",
    "        datasets = [build_ds(self.cfg_.data.train)]\n",
    "        self.model_.CLASSES = datasets[0].CLASSES\n",
    "        \n",
    "        # training params\n",
    "        self.cfg_.runner.max_epochs = n_epochs\n",
    "        train_segmentor(self.model_, datasets, self.cfg_, distributed=False, validate=True, meta=dict())\n",
    "    \n",
    "    @AOP.excepter(NotImplementedError)\n",
    "    def fit_one_cycle(self, n_epochs = 10):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Trains a model with decrease - increase learning rates.\n",
    "        \n",
    "        Parameters:\n",
    "        n_epochs (int, 10): the number of epochs.\n",
    "        \n",
    "        Returns:\n",
    "        None.\n",
    "        \"\"\"\n",
    "        self.fit(n_epochs)\n",
    "\n",
    "    @AOP.excepter(NotImplementedError)\n",
    "    def fine_tune(self, n_epochs = 10, n_freeze_epochs = 1):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Trains a model using fine tune technique.\n",
    "        \n",
    "        Parameters:\n",
    "        n_epochs (int, 10): the number of epochs.\n",
    "        n_freeze_epochs (int, 1): the number of freeze epochs.\n",
    "        \n",
    "        Returns:\n",
    "        None.\n",
    "        \"\"\"\n",
    "        # the dataset\n",
    "        datasets = [build_ds(self.cfg_.data.train)]\n",
    "        self.model_.CLASSES = datasets[0].CLASSES\n",
    "        \n",
    "        # Fine tune\n",
    "        self.cfg_.load_from = self.weights_\n",
    "        \n",
    "        # training params\n",
    "        self.cfg_.runner.max_epochs = n_epochs\n",
    "        train_segmentor(self.model_, datasets, self.cfg_, distributed=False, validate=True, meta=dict())\n",
    "    \n",
    "    @AOP.excepter(NotImplementedError)\n",
    "    def validate(self, test_dls):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Validates a model with the test_dls DataLoader.\n",
    "        \n",
    "        Params:\n",
    "        test_dls (DataLoader): the DataLoader used to validate the model.\n",
    "        \n",
    "        Returns:\n",
    "        None.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Those models validate themselves while training.\")\n",
    "    \n",
    "    @AOP.excepter(NotImplementedError)\n",
    "    def save(self, name):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Saves the model in the checkpoints file.\n",
    "        \n",
    "        Parameters:\n",
    "        name (str): the name to give to the model.\n",
    "        \n",
    "        Returns:\n",
    "        The path to the saved model.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Those models save themselves while training.\")\n",
    "    \n",
    "    @AOP.excepter(NotImplementedError)\n",
    "    def load(self, model):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Loads a model with a checkpoint file.\n",
    "        \n",
    "        Parameters:\n",
    "        model (str): the path to the checkpoint.\n",
    "        \n",
    "        Returns:\n",
    "        None.\n",
    "        \"\"\"\n",
    "        self.cfg_.resume_from = model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
