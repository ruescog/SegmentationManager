{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import shutil\n",
    "import os.path as osp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is an \"import\" in .py files\n",
    "%run utils.ipynb\n",
    "%run DatasetManager.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidationManager():\n",
    "    \"\"\"\n",
    "    Defines the way the files are splitted into train and test groups.\n",
    "    \"\"\"\n",
    "    def __init__(self, train_size = 0.9, test_size = 0.1, shuffle = True, random_state = None):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Builds the ValidationManager.\n",
    "        \n",
    "        Parameters:\n",
    "        train_size (float, 0.9): the number of images in the train set.\n",
    "        test_size (float, 0.1): the number of images in the test set.\n",
    "        shuffle (boolean, True): if the data must be splitted.\n",
    "        random_state (int, None): random seed for results reproducibility.\n",
    "        \n",
    "        Returns:\n",
    "        vm (ValidationManager): the built ValidationManager.\n",
    "        \"\"\"\n",
    "        self.train_size_ = train_size\n",
    "        self.test_size_ = test_size\n",
    "        self.shuffle_ = shuffle\n",
    "        self.random_state_ = random_state\n",
    "    \n",
    "    def __normalize__(*values):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Normalizes a list of values.\n",
    "        \n",
    "        Parameters:\n",
    "        values (float, float, ..., float): the values to normalize.\n",
    "        \n",
    "        Returns:\n",
    "        values (list[float]): a list with the normalized values.\n",
    "        \"\"\"\n",
    "        total = sum(values)\n",
    "        if total != 1:\n",
    "            values = [value / total for value in values]\n",
    "        \n",
    "        return values\n",
    "    \n",
    "    def __get_indexes__(total_len, *splits):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Gets the index of each split.\n",
    "        \n",
    "        Parameters:\n",
    "        total_len (int): the total len of the data.\n",
    "        splits (float, float, ..., float): the data percentage for each split.\n",
    "        \n",
    "        Returns:\n",
    "        indexes (list(int)): a list with the final index for each split.\n",
    "        \"\"\"\n",
    "        except_last = [int(total_len * sum(splits[:index+1])) for index, split in enumerate(splits[:-1])]\n",
    "        return except_last + [total_len]\n",
    "    \n",
    "    def __get_slices__(*indexes):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Gets the slices making intevals between indexes.\n",
    "        \n",
    "        Parameters:\n",
    "        indexes (int, int, ..., int): the indexes to make the union.\n",
    "        \n",
    "        Returns:\n",
    "        slices (list[slice]): a list with all the slices.\n",
    "        \"\"\"\n",
    "        \n",
    "        return [slice(start, end) for start, end in zip(indexes[:-1], indexes[1:])]\n",
    "    \n",
    "    def __make_validation_structure__(splits_dir, replications = 1):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Makes the structure for the validation.\n",
    "        \n",
    "        Parameters:\n",
    "        splits_dir (str): path like. Where the splits are going to be done.\n",
    "        replications (int): the number of training groups.\n",
    "        \n",
    "        Returns:\n",
    "        None.\n",
    "        \"\"\"\n",
    "        # creates an empty split root directory\n",
    "        if osp.isdir(splits_dir):\n",
    "            shutil.rmtree(splits_dir)\n",
    "        \n",
    "        os.mkdir(splits_dir)\n",
    "        \n",
    "        # creates the new splits directories, one for each replication\n",
    "        for index in range(1, replications + 1):\n",
    "            os.mkdir(osp.join(splits_dir, f\"f_{index}\"))\n",
    "            \n",
    "    def __get_splits_dict__(splits_names):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Gets the structure's dict of the splits directory.\n",
    "        \n",
    "        Parameters:\n",
    "        splits_names (list[list[str]]): the list with the splits directories.\n",
    "        \n",
    "        Returns:\n",
    "        d (dict): the structure's dict.\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        for index, names in enumerate(splits_names):\n",
    "            if len(names) == 2:\n",
    "                results.update({f\"f_{index+1}\": {\"train\": names[0], \"val\": names[1]}})\n",
    "            else:\n",
    "                results.update({\"test\": names[0]})\n",
    "        \n",
    "        return results\n",
    "\n",
    "    @AOP.excepter(NotImplementedError)\n",
    "    def split(self, dataset):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Makes the splits.\n",
    "        \n",
    "        Parameters:\n",
    "        dataset (DatasetManager): the dataset where the data is.\n",
    "\n",
    "        Returns:\n",
    "        None.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"You can not use this abstract class to make the split.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidationManagerTrainValTest(ValidationManager):\n",
    "    \"\"\"\n",
    "    Defines the way the files are splitted into train and validation groups.\n",
    "    \"\"\"\n",
    "    def __init__(self, train_size = 0.75, val_size = 0.15, test_size = 0.1,\n",
    "                 shuffle = True, random_state = None):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Builts the ValidationManagerTrainValTest.\n",
    "        \n",
    "        Parameters:\n",
    "        train_size (int | Float, 0.75): the number of images in the train set.\n",
    "        val_size (int | Float, 0.15): the number of images in the validation set.\n",
    "        test_size (int | Float, 0.1): the number of images in the test set.\n",
    "        shuffle (boolean, True): if the data must be splitted.\n",
    "        random_state (int, None): random seed for results reproducibility.\n",
    "        \n",
    "        Returns:\n",
    "        vm (ValidationManagerTrainValTest): The built ValidationManagerTrainValTest.\n",
    "        \"\"\"\n",
    "        super().__init__(train_size, test_size, shuffle, random_state)\n",
    "        self.val_size_ = val_size\n",
    "\n",
    "    def split(self, dataset):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Makes 3 splits in the dataset: train, validation and test.\n",
    "        \n",
    "        Parameters:\n",
    "        dataset (DatasetManager): the dataset where the data is.\n",
    "        \n",
    "        Returns:\n",
    "        split_result (dict): the split structure.\n",
    "        \"\"\"\n",
    "        # normalizes the sizes\n",
    "        normalized_sizes = ValidationManager.__normalize__(self.train_size_, self.val_size_, self.test_size_)\n",
    "        self.train_size_, self.val_size_, self.test_size_ = normalized_sizes\n",
    "\n",
    "        # gets the real number of images in each split\n",
    "        ds_images = dataset.get_images()\n",
    "        train_index, val_index, test_index = ValidationManager.__get_indexes__(len(ds_images), *normalized_sizes)\n",
    "        \n",
    "        # shuffles it if requested\n",
    "        if self.shuffle_:\n",
    "            if self.random_state_:\n",
    "                np.random.seed(self.random_state_)\n",
    "            np.random.shuffle(ds_images)\n",
    "\n",
    "        # saves the split result\n",
    "        splits_dir = osp.join(dataset.root_dir_, \"splits\")\n",
    "        splits_names = [\"f_1/train.txt\", \"f_1/val.txt\", \"test.txt\"]\n",
    "        splits_slices = ValidationManager.__get_slices__(0, train_index, val_index, test_index)\n",
    "\n",
    "        # creates the splits structure\n",
    "        ValidationManager.__make_validation_structure__(splits_dir, 1)\n",
    "\n",
    "        # saves all the splits: for each filename\n",
    "        for file_name, index in zip(splits_names, splits_slices):\n",
    "            # opens it\n",
    "            with open(osp.join(splits_dir, file_name), \"w\") as file:\n",
    "                # saves all the images path\n",
    "                for img in ds_images[index]:\n",
    "                    file.write(osp.basename(img).split(\".\")[0] + \"\\n\")\n",
    "\n",
    "        # returns a dictionary with the structure of the split directory\n",
    "        return ValidationManager.__get_splits_dict__([[*splits_names[:-1]], [splits_names[-1]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidationManagerKFold(ValidationManager):\n",
    "    \"\"\"\n",
    "    Defines the way the files are splitted into k groups of train and validation sets.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, train_size = 0.9, test_size = 0.1, n_splits = 5,\n",
    "                 shuffle = True, random_state = None):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Builts the ValidationManagerTrainValTest.\n",
    "        \n",
    "        Parameters:\n",
    "        train_size (int | Float, 0.9): the number of images in the train set.\n",
    "        test_size (int | Float, 0.1): the number of images in the test set.\n",
    "        n_splits (int, 5): the number of folds used in KFold validation.\n",
    "        shuffle (boolean, True): if the data must be splitted.\n",
    "        random_state (int, None): random seed for results reproducibility.\n",
    "        \n",
    "        Returns:\n",
    "        vm (ValidationManagerKFold): The built ValidationManagerKFold.\n",
    "        \"\"\"\n",
    "        super().__init__(train_size, test_size, shuffle, random_state)\n",
    "        self.n_splits_ = n_splits if n_splits >= 2 else 5\n",
    " \n",
    "    def split(self, dataset):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "        Makes KFold validation splits.\n",
    "\n",
    "        Parameters:\n",
    "        dataset (DatasetManager): the dataset where the data is.\n",
    "        \n",
    "        Returns:\n",
    "        split_result (dict): the split structure.\n",
    "        \"\"\"\n",
    "        # normalizes the sizes\n",
    "        normalized_sizes = ValidationManager.__normalize__(self.train_size_, self.test_size_)\n",
    "        self.train_size_, self.test_size_ = normalized_sizes\n",
    "        \n",
    "        # gets the total number of images\n",
    "        ds_images = dataset.get_images()\n",
    "\n",
    "        # gets the split index for each fold\n",
    "        train_index, test_index = ValidationManager.__get_indexes__(len(ds_images), *normalized_sizes)\n",
    "        train_index_i = list(np.cumsum([int(train_index / self.n_splits_)] * self.n_splits_))\n",
    "\n",
    "        # the last fold can be a little bigger (just like the test size)\n",
    "        train_index_i[-1] = train_index\n",
    "        \n",
    "        # shuffles it if requested\n",
    "        if self.shuffle_:\n",
    "            if self.random_state_:\n",
    "                np.random.seed(self.random_state_)\n",
    "            np.random.shuffle(ds_images)\n",
    "        \n",
    "        # gets the splits directory name\n",
    "        splits_dir = osp.join(dataset.root_dir_, \"splits\")\n",
    "        \n",
    "        # gets all the folds directories names\n",
    "        splits_names = [[f\"f_{index}/train.txt\", f\"f_{index}/val.txt\"] for index in range(1, self.n_splits_ + 1)]\n",
    "        splits_names.append([\"test.txt\"])\n",
    "        \n",
    "        # gets all the slices for each fold (f fold train - validation) except the test slice\n",
    "        splits_slices = ValidationManager.__get_slices__(0, *train_index_i)\n",
    "        \n",
    "        # creates a list of list where each element is a list of train slices and a list with the validation slice\n",
    "        # splits_slices = [[[train_slice_1, train_slice_2, ..., train_slice_n], [validation_slice]], ...]\n",
    "        splits_slices = [[[s_ for s_ in splits_slices if s_ != s], [s]] for s in splits_slices]\n",
    "        \n",
    "        # appends the test slice to the result\n",
    "        splits_slices.append([[slice(train_index_i[-1], test_index)]])\n",
    "        \n",
    "        # creates the splits structure\n",
    "        ValidationManager.__make_validation_structure__(splits_dir, self.n_splits_)\n",
    "\n",
    "        # saves all the splits\n",
    "        for file_names, split_slices in zip(splits_names, splits_slices):\n",
    "            for file_name, slices in zip(file_names, split_slices):\n",
    "                with open(osp.join(splits_dir, file_name), \"w\") as file:\n",
    "                    for s in slices:\n",
    "                        for img in ds_images[s]:\n",
    "                            file.write(osp.basename(img).split(\".\")[0] + \"\\n\")\n",
    "\n",
    "        # returns the names dict\n",
    "        return ValidationManager.__get_splits_dict__(splits_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
